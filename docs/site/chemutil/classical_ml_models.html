<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />


  <title>chemutil.classical_ml_models API documentation</title>
  <meta name="description" content="Module for deepchem model building" />


  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>

  <style type="text/css">
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}
</style>
  <style type="text/css">
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  }

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; }

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;

      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/
</style>
  <style type="text/css">
  pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #F00 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #04D } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */
.codehilite .no { color: #800 } /* Name.Constant */
.codehilite .nd { color: #A2F } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #00F } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #BBB } /* Text.Whitespace */
.codehilite .mb { color: #666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666 } /* Literal.Number.Float */
.codehilite .mh { color: #666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #00F } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */
  </style>
  <style type="text/css">
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}
</style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>
<div id="container">




















  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">
    <li class="set"><h3>Super-module</h3>
      <ul>
        <li class="mono"><a href="index.html">chemutil</a></li>
      </ul>
    </li>
    <li class="set"><h3><a href="#header-variables">Module variables</a></h3>

  <ul>
    <li class="mono"><a href="#chemutil.classical_ml_models.log">log</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>

  <ul>
    <li class="mono"><a href="#chemutil.classical_ml_models.bayesian_models">bayesian_models</a></li>
    <li class="mono"><a href="#chemutil.classical_ml_models.ensemble_models">ensemble_models</a></li>
    <li class="mono"><a href="#chemutil.classical_ml_models.get_models">get_models</a></li>
    <li class="mono"><a href="#chemutil.classical_ml_models.kernel_models">kernel_models</a></li>
    <li class="mono"><a href="#chemutil.classical_ml_models.linear_models">linear_models</a></li>
    <li class="mono"><a href="#chemutil.classical_ml_models.neural_network_models">neural_network_models</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#chemutil.classical_ml_models.skmodel">skmodel</a></span>

        </li>
      </ul>
    </li>

    </ul>
  </div>

<article id="content">





  <header id="section-intro">
  <h1 class="title"><span class="name">chemutil.classical_ml_models</span> module</h1>
  <p>Module for deepchem model building</p>

  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models" class="source">
    <div class="codehilite"><pre><span></span><span class="ch">#!/usr/bin.env python3</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Module for deepchem model building</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sklearn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AdaBoostRegressor</span><span class="p">,</span>
    <span class="n">ExtraTreesRegressor</span><span class="p">,</span>
    <span class="n">HistGradientBoostingRegressor</span><span class="p">,</span>
    <span class="n">RandomForestRegressor</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process.kernels</span><span class="w"> </span><span class="kn">import</span> <span class="n">RBF</span><span class="p">,</span> <span class="n">Matern</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.kernel_ridge</span><span class="w"> </span><span class="kn">import</span> <span class="n">KernelRidge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BayesianRidge</span><span class="p">,</span>
    <span class="n">Lars</span><span class="p">,</span>
    <span class="n">Lasso</span><span class="p">,</span>
    <span class="n">LinearRegression</span><span class="p">,</span>
    <span class="n">ARDRegression</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xgboost</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">lightgbm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightgbm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">ExtraTreeRegressor</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">chemutil</span><span class="w"> </span><span class="kn">import</span> <span class="n">helpers</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="c1"># Data class to contain an sklearn regressor model. The class allows for a default hyper parameter grid to trained over or for a cutom one to be added without loosing the default.</span>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">skmodel</span><span class="p">:</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span>
    <span class="n">default_param_grid</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">custom_param_grid</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">multi_output_regressor</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">more_info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">sklearn_version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span>
    <span class="n">date</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_models</span><span class="p">(</span>
    <span class="n">linear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">kernel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">bayesian</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">ensemble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">neural_network</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">n_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">prepend_parameter_keys_with_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">multi_output_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prepend_with</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;model__&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to return a list of models to train over and trial</span>

<span class="sd">    Args:</span>
<span class="sd">        linear (bool, optional): Return linear models. Defaults to True.</span>
<span class="sd">        kernel (bool, optional): Return kernel models. Defaults to True.</span>
<span class="sd">        bayesian (bool, optional): Return Bayesian models. Defaults to True.</span>
<span class="sd">        ensemble (bool, optional): Return ensemble models. Defaults to True.</span>
<span class="sd">        neural_network (bool, optional): Return neural network models. Defaults to True.</span>
<span class="sd">        n_features (Optional[int], optional): The number of input features. Used in Bayesian model Gaussian process to allow the use for anisotropic kernels. Defaults to None.</span>
<span class="sd">        n_targets (Optional[int], optional): The number of targets. Used in Bayesian model Gaussian process to set the expected number of outputs. Defaults to 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List: List of sklearn models wrapped in a custom dataclass with meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">linear</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">linear_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">kernel_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">bayesian</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">bayesian_models</span><span class="p">(</span>
            <span class="n">n_targets</span><span class="o">=</span><span class="n">n_targets</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">ensemble</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">ensemble_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neural_network</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">neural_network_models</span><span class="p">(</span><span class="n">n_input_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prepend_parameter_keys_with_model</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
            <span class="n">m</span><span class="o">.</span><span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend_with</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_grid</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">m</span><span class="o">.</span><span class="n">custom_param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend_with</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">custom_param_grid</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="k">if</span> <span class="n">multi_output_only</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">multi_output_regressor</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">models</span>


<span class="k">def</span><span class="w"> </span><span class="nf">linear_models</span><span class="p">(</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">lasso</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">lars</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of linear models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of linear models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Linear regression</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">LinearRegression</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">lasso</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Lasso - tresting selection as a hyper-parameter as random selection can significantly increase convergence time so may enable models to converge that wouldn&#39;t otherwise</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">Lasso</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">Lasso</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="s2">&quot;selection&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cyclic&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">]},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">lars</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Lars</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">Lars</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">Lars</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;n_nonzero_coefs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="s2">&quot;jitter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>


<span class="k">def</span><span class="w"> </span><span class="nf">kernel_models</span><span class="p">(</span>
    <span class="n">kr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">svr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">svm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of kernel models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of kernel models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">kr</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Pair wise kernel metric strings: ‘additive_chi2’, ‘chi2’, ‘linear’, ‘poly’, ‘polynomial’, ‘rbf’, ‘laplacian’, ‘sigmoid’, ‘cosine’</span>
        <span class="c1"># kernel ridge</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">KernelRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">KernelRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># kernel ridge - polynomical kernel has the degree parameter so we separate the model</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">KernelRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;poly_kernel&quot;</span><span class="p">,</span>
                <span class="n">KernelRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;poly&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                    <span class="s2">&quot;degree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">svr</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">or</span> <span class="n">svm</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Support Vector Regression (SVR)</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">SVR</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">SVR</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span>
                    <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Support Vector Regression (SVR) - polynomical kernel has the degree parameter so we separate the model</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">SVR</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;poly_kernel&quot;</span><span class="p">,</span>
                <span class="n">SVR</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;poly&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span>
                    <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;degree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>


<span class="k">def</span><span class="w"> </span><span class="nf">bayesian_models</span><span class="p">(</span>
    <span class="n">br</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">ard</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">gp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">n_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_restarts_optimizer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of Bayesian models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of Bayesian models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">br</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># BayesianRidge - Note this is in effect a linear model with a probablistic view point i.e. we get a mean and a std as model is ineffect covering a range of predictive functions</span>
        <span class="c1"># https://scikit-learn.org/stable/auto_examples/linear_model/plot_bayesian_ridge_curvefit.html#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-curvefit-py</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">BayesianRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">BayesianRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;alpha_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Automatic Relevance Determination (Relevance Vector Machine)</span>
    <span class="k">if</span> <span class="n">ard</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">ARDRegression</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">ARDRegression</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;alpha_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;alpha_2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">gp</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Gaussian process</span>
        <span class="c1"># If we know the number of features we can use an anisotropic kernel amd an isotropic kernel otherwise we can only use an isotropic kernel</span>
        <span class="k">if</span> <span class="n">n_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span>
            <span class="c1"># NOTE: None uses the default Constant kernel(1.0) * RBF(length_scale=1.0) with fixed length scales. The last kernel allows length scale optimization</span>
            <span class="c1"># using the RBF kernel</span>
            <span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="p">]</span>

        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">GaussianProcessRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                    <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="n">n_restarts_optimizer</span><span class="p">,</span>
                    <span class="n">n_targets</span><span class="o">=</span><span class="n">n_targets</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="n">kernels</span><span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ensemble_models</span><span class="p">(</span>
    <span class="n">adb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">rf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">et</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">hgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">xgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">lgbm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of ensemble models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of ensemble models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">rf</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Random forest</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">RandomForestRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">RandomForestRegressor</span><span class="p">(</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
                    <span class="s2">&quot;ccp_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                    <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                    <span class="s2">&quot;max_samples&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">et</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Extra trees regressor</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">ExtraTreesRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">ExtraTreesRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
                    <span class="s2">&quot;ccp_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                    <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">adb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Adaboost</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">AdaBoostRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                        <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                    <span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span>
                    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;square&quot;</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">hgb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Gradient boosting - This version is similar to LightGBM</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">HistGradientBoostingRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">HistGradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                    <span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="s2">&quot;l2_regularization&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span>
                    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;squared_error&quot;</span><span class="p">,</span> <span class="s2">&quot;absolute_error&quot;</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">xgb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># EXtreme Gradient Boosting - Model tuning guide https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning</span>
        <span class="c1"># early stopping https://xgboosting.com/configure-xgboost-early-stopping-regularization/</span>
        <span class="c1"># training https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/#:~:text=The%20number%20of%20trees%20(or,the%20XGBoost%20library%20is%20100.</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">XGBRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                    <span class="s2">&quot;min_child_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
                    <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;colsample_bytree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_lambda&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://xgboost.readthedocs.io/en/stable/python/python_api.html&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;XGBoost version: </span><span class="si">{</span><span class="n">xgboost</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># {</span>
        <span class="c1">#             &quot;n_estimators&quot;: [100, 200, 500],</span>
        <span class="c1">#             &quot;max_depth&quot;: [3, 5, 7],</span>
        <span class="c1">#             &quot;min_child_weight&quot;: [1, 2, 3],</span>
        <span class="c1">#             &quot;gamma&quot;: [0, 0.05, 0.1],</span>
        <span class="c1">#             &quot;subsample&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;reg_alpha&quot;: [0.0, 0.1, 0.2],</span>
        <span class="c1">#             &quot;reg_lambda&quot;: [1.0, 1.1, 1.2],</span>
        <span class="c1">#         },</span>

        <span class="c1"># {</span>
        <span class="c1">#     &quot;n_estimators&quot;: [100, 250, 500, 750, 1000],</span>
        <span class="c1">#     &quot;learning_rate&quot;: [0.2, 0.3, 0.4],</span>
        <span class="c1">#     &quot;max_depth&quot;: [3, 5, 7],</span>
        <span class="c1">#     &quot;min_child_weight&quot;: [1, 2, 3],</span>
        <span class="c1">#     &quot;gamma&quot;: [0, 0.05, 0.1],</span>
        <span class="c1">#     &quot;subsample&quot;: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],</span>
        <span class="c1">#     &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#     &quot;reg_alpha&quot;: [0.0, 0.1, 0.25, 0.4],</span>
        <span class="c1">#     &quot;reg_lambda&quot;: [1.0, 1.1, 1.25, 1.4],</span>
        <span class="c1">#     &quot;grow_policy&quot;: [&quot;depthwise&quot;, &quot;lossguide&quot;],</span>
        <span class="c1"># },</span>

    <span class="k">if</span> <span class="n">lgbm</span><span class="p">:</span>
        <span class="c1"># Light Gradient Boosting Machine - Model tuning guide https://www.kaggle.com/code/bextuychiev/lgbm-optuna-hyperparameter-tuning-w-understanding</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">LGBMRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                    <span class="s2">&quot;num_leaves&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                    <span class="s2">&quot;min_data_in_leaf&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
                    <span class="s2">&quot;reg_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_lambda&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;LightGBM version: </span><span class="si">{</span><span class="n">lightgbm</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># {</span>
        <span class="c1">#             &quot;learning_rate&quot;: [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],</span>
        <span class="c1">#             &quot;n_estimators&quot;: [100, 150, 200],</span>
        <span class="c1">#             &quot;max_depth&quot;: [-1, 3, 5, 7],</span>
        <span class="c1">#             &quot;num_leaves&quot;: [15, 31, 45, 60],</span>
        <span class="c1">#             &quot;min_child_samples&quot;: [10, 20, 30],</span>
        <span class="c1">#             &quot;subsample&quot;: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],</span>
        <span class="c1">#             &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;reg_alpha&quot;: [0.0, 1.0, 10.0, 100.0],</span>
        <span class="c1">#             &quot;reg_lambda&quot;: [0.0, 1.0, 10.0, 100.0],</span>
        <span class="c1">#         },</span>

    <span class="k">return</span> <span class="n">models</span>


<span class="k">def</span><span class="w"> </span><span class="nf">neural_network_models</span><span class="p">(</span>
    <span class="n">mlp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">layers</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">n_input_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">skip_feature_n_dependent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">     Function to build a default set of neural network models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of neural network models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_input_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">skip_feature_n_dependent</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">hl1</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]</span>
        <span class="n">hl2</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>
        <span class="n">hl3</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hl1</span><span class="p">[</span><span class="n">ith</span><span class="p">],</span> <span class="n">hl2</span><span class="p">[</span><span class="n">ith</span><span class="p">],</span> <span class="n">hl3</span><span class="p">[</span><span class="n">ith</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">mlp</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Multi-layer perceptron (MLP) - This is the only general NN in sklearn currently. It is built as feedforward network.</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">MLPRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">MLPRegressor</span><span class="p">(</span>
                    <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span>
                <span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;const&quot;</span><span class="p">,</span> <span class="s2">&quot;invscaling&quot;</span><span class="p">,</span> <span class="s2">&quot;adaptive&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;learning_rate_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.00001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span>
                    <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">:</span> <span class="n">layers</span><span class="p">,</span>
                    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">
    <h2 class="section-title" id="header-variables">Module variables</h2>
      <div class="item">
      <p id="chemutil.classical_ml_models.log" class="name">var <span class="ident">log</span></p>


  <div class="source_cont">
</div>

      </div>

    <h2 class="section-title" id="header-functions">Functions</h2>

  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.bayesian_models">
    <p>def <span class="ident">bayesian_models</span>(</p><p>br: bool = True, ard: bool = True, gp: bool = True, n_targets: int = 1, n_features: Optional[int] = None, n_restarts_optimizer: int = 5, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to build a default set of Bayesian models and parameter grids to optimize the models over</p>
<p>Returns:
    List[skmodel]: List of Bayesian models and meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.bayesian_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.bayesian_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bayesian_models</span><span class="p">(</span>
    <span class="n">br</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">ard</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">gp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">n_targets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">n_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_restarts_optimizer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of Bayesian models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of Bayesian models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">br</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># BayesianRidge - Note this is in effect a linear model with a probablistic view point i.e. we get a mean and a std as model is ineffect covering a range of predictive functions</span>
        <span class="c1"># https://scikit-learn.org/stable/auto_examples/linear_model/plot_bayesian_ridge_curvefit.html#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-curvefit-py</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">BayesianRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">BayesianRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;alpha_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Automatic Relevance Determination (Relevance Vector Machine)</span>
    <span class="k">if</span> <span class="n">ard</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">ARDRegression</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">ARDRegression</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;alpha_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;alpha_2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                    <span class="s2">&quot;lambda_2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="mf">1.0e-10</span><span class="p">,</span> <span class="mf">1.0e-4</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">gp</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Gaussian process</span>
        <span class="c1"># If we know the number of features we can use an anisotropic kernel amd an isotropic kernel otherwise we can only use an isotropic kernel</span>
        <span class="k">if</span> <span class="n">n_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span>
            <span class="c1"># NOTE: None uses the default Constant kernel(1.0) * RBF(length_scale=1.0) with fixed length scales. The last kernel allows length scale optimization</span>
            <span class="c1"># using the RBF kernel</span>
            <span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">ls</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kernels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="p">]</span>

        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">GaussianProcessRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                    <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="n">n_restarts_optimizer</span><span class="p">,</span>
                    <span class="n">n_targets</span><span class="o">=</span><span class="n">n_targets</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="n">kernels</span><span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.ensemble_models">
    <p>def <span class="ident">ensemble_models</span>(</p><p>adb: bool = True, rf: bool = True, et: bool = True, hgb: bool = True, xgb: bool = True, lgbm: bool = True, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to build a default set of ensemble models and parameter grids to optimize the models over</p>
<p>Returns:
    List[skmodel]: List of ensemble models and meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.ensemble_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.ensemble_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">ensemble_models</span><span class="p">(</span>
    <span class="n">adb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">rf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">et</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">hgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">xgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">lgbm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of ensemble models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of ensemble models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">rf</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Random forest</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">RandomForestRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">RandomForestRegressor</span><span class="p">(</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
                    <span class="s2">&quot;ccp_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                    <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                    <span class="s2">&quot;max_samples&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">et</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Extra trees regressor</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">ExtraTreesRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">ExtraTreesRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
                    <span class="s2">&quot;ccp_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
                    <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">,</span> <span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">adb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Adaboost</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">AdaBoostRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                        <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                    <span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span>
                    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;square&quot;</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">hgb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Gradient boosting - This version is similar to LightGBM</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">HistGradientBoostingRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">HistGradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                    <span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="s2">&quot;l2_regularization&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span>
                    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;squared_error&quot;</span><span class="p">,</span> <span class="s2">&quot;absolute_error&quot;</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">xgb</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># EXtreme Gradient Boosting - Model tuning guide https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning</span>
        <span class="c1"># early stopping https://xgboosting.com/configure-xgboost-early-stopping-regularization/</span>
        <span class="c1"># training https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/#:~:text=The%20number%20of%20trees%20(or,the%20XGBoost%20library%20is%20100.</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">XGBRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                    <span class="s2">&quot;min_child_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
                    <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;colsample_bytree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_lambda&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://xgboost.readthedocs.io/en/stable/python/python_api.html&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;XGBoost version: </span><span class="si">{</span><span class="n">xgboost</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># {</span>
        <span class="c1">#             &quot;n_estimators&quot;: [100, 200, 500],</span>
        <span class="c1">#             &quot;max_depth&quot;: [3, 5, 7],</span>
        <span class="c1">#             &quot;min_child_weight&quot;: [1, 2, 3],</span>
        <span class="c1">#             &quot;gamma&quot;: [0, 0.05, 0.1],</span>
        <span class="c1">#             &quot;subsample&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;reg_alpha&quot;: [0.0, 0.1, 0.2],</span>
        <span class="c1">#             &quot;reg_lambda&quot;: [1.0, 1.1, 1.2],</span>
        <span class="c1">#         },</span>

        <span class="c1"># {</span>
        <span class="c1">#     &quot;n_estimators&quot;: [100, 250, 500, 750, 1000],</span>
        <span class="c1">#     &quot;learning_rate&quot;: [0.2, 0.3, 0.4],</span>
        <span class="c1">#     &quot;max_depth&quot;: [3, 5, 7],</span>
        <span class="c1">#     &quot;min_child_weight&quot;: [1, 2, 3],</span>
        <span class="c1">#     &quot;gamma&quot;: [0, 0.05, 0.1],</span>
        <span class="c1">#     &quot;subsample&quot;: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],</span>
        <span class="c1">#     &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#     &quot;reg_alpha&quot;: [0.0, 0.1, 0.25, 0.4],</span>
        <span class="c1">#     &quot;reg_lambda&quot;: [1.0, 1.1, 1.25, 1.4],</span>
        <span class="c1">#     &quot;grow_policy&quot;: [&quot;depthwise&quot;, &quot;lossguide&quot;],</span>
        <span class="c1"># },</span>

    <span class="k">if</span> <span class="n">lgbm</span><span class="p">:</span>
        <span class="c1"># Light Gradient Boosting Machine - Model tuning guide https://www.kaggle.com/code/bextuychiev/lgbm-optuna-hyperparameter-tuning-w-understanding</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">LGBMRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                    <span class="s2">&quot;num_leaves&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                    <span class="s2">&quot;min_data_in_leaf&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
                    <span class="s2">&quot;reg_alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                    <span class="s2">&quot;reg_lambda&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;LightGBM version: </span><span class="si">{</span><span class="n">lightgbm</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># {</span>
        <span class="c1">#             &quot;learning_rate&quot;: [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],</span>
        <span class="c1">#             &quot;n_estimators&quot;: [100, 150, 200],</span>
        <span class="c1">#             &quot;max_depth&quot;: [-1, 3, 5, 7],</span>
        <span class="c1">#             &quot;num_leaves&quot;: [15, 31, 45, 60],</span>
        <span class="c1">#             &quot;min_child_samples&quot;: [10, 20, 30],</span>
        <span class="c1">#             &quot;subsample&quot;: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],</span>
        <span class="c1">#             &quot;colsample_bytree&quot;: [0.6, 0.8, 1.0],</span>
        <span class="c1">#             &quot;reg_alpha&quot;: [0.0, 1.0, 10.0, 100.0],</span>
        <span class="c1">#             &quot;reg_lambda&quot;: [0.0, 1.0, 10.0, 100.0],</span>
        <span class="c1">#         },</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.get_models">
    <p>def <span class="ident">get_models</span>(</p><p>linear: bool = True, kernel: bool = True, bayesian: bool = True, ensemble: bool = True, neural_network: bool = True, n_features: Optional[int] = None, n_targets: Optional[int] = 1, prepend_parameter_keys_with_model: bool = False, multi_output_only: bool = False, prepend_with: str = &#39;model__&#39;, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to return a list of models to train over and trial</p>
<p>Args:
    linear (bool, optional): Return linear models. Defaults to True.
    kernel (bool, optional): Return kernel models. Defaults to True.
    bayesian (bool, optional): Return Bayesian models. Defaults to True.
    ensemble (bool, optional): Return ensemble models. Defaults to True.
    neural_network (bool, optional): Return neural network models. Defaults to True.
    n_features (Optional[int], optional): The number of input features. Used in Bayesian model Gaussian process to allow the use for anisotropic kernels. Defaults to None.
    n_targets (Optional[int], optional): The number of targets. Used in Bayesian model Gaussian process to set the expected number of outputs. Defaults to 1.</p>
<p>Returns:
    List: List of sklearn models wrapped in a custom dataclass with meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.get_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.get_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_models</span><span class="p">(</span>
    <span class="n">linear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">kernel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">bayesian</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">ensemble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">neural_network</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">n_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">prepend_parameter_keys_with_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">multi_output_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prepend_with</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;model__&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to return a list of models to train over and trial</span>

<span class="sd">    Args:</span>
<span class="sd">        linear (bool, optional): Return linear models. Defaults to True.</span>
<span class="sd">        kernel (bool, optional): Return kernel models. Defaults to True.</span>
<span class="sd">        bayesian (bool, optional): Return Bayesian models. Defaults to True.</span>
<span class="sd">        ensemble (bool, optional): Return ensemble models. Defaults to True.</span>
<span class="sd">        neural_network (bool, optional): Return neural network models. Defaults to True.</span>
<span class="sd">        n_features (Optional[int], optional): The number of input features. Used in Bayesian model Gaussian process to allow the use for anisotropic kernels. Defaults to None.</span>
<span class="sd">        n_targets (Optional[int], optional): The number of targets. Used in Bayesian model Gaussian process to set the expected number of outputs. Defaults to 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List: List of sklearn models wrapped in a custom dataclass with meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">linear</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">linear_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">kernel_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">bayesian</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">bayesian_models</span><span class="p">(</span>
            <span class="n">n_targets</span><span class="o">=</span><span class="n">n_targets</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">ensemble</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">ensemble_models</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">neural_network</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="n">models</span> <span class="o">+</span> <span class="n">neural_network_models</span><span class="p">(</span><span class="n">n_input_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prepend_parameter_keys_with_model</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
            <span class="n">m</span><span class="o">.</span><span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend_with</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_grid</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">m</span><span class="o">.</span><span class="n">custom_param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend_with</span><span class="si">}{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">custom_param_grid</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="k">if</span> <span class="n">multi_output_only</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">multi_output_regressor</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.kernel_models">
    <p>def <span class="ident">kernel_models</span>(</p><p>kr: bool = True, svr: bool = True, svm: bool = False, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to build a default set of kernel models and parameter grids to optimize the models over</p>
<p>Returns:
    List[skmodel]: List of kernel models and meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.kernel_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.kernel_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">kernel_models</span><span class="p">(</span>
    <span class="n">kr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">svr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">svm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of kernel models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of kernel models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">kr</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Pair wise kernel metric strings: ‘additive_chi2’, ‘chi2’, ‘linear’, ‘poly’, ‘polynomial’, ‘rbf’, ‘laplacian’, ‘sigmoid’, ‘cosine’</span>
        <span class="c1"># kernel ridge</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">KernelRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">KernelRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># kernel ridge - polynomical kernel has the degree parameter so we separate the model</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">KernelRidge</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;poly_kernel&quot;</span><span class="p">,</span>
                <span class="n">KernelRidge</span><span class="p">(),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;poly&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                    <span class="s2">&quot;degree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">svr</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">or</span> <span class="n">svm</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Support Vector Regression (SVR)</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">SVR</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">SVR</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span>
                    <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Support Vector Regression (SVR) - polynomical kernel has the degree parameter so we separate the model</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">SVR</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;poly_kernel&quot;</span><span class="p">,</span>
                <span class="n">SVR</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;poly&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span>
                    <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                    <span class="s2">&quot;degree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.linear_models">
    <p>def <span class="ident">linear_models</span>(</p><p>lr: bool = True, lasso: bool = True, lars: bool = True, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to build a default set of linear models and parameter grids to optimize the models over</p>
<p>Returns:
    List[skmodel]: List of linear models and meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.linear_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.linear_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">linear_models</span><span class="p">(</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">lasso</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">lars</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build a default set of linear models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of linear models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Linear regression</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">LinearRegression</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">{},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">lasso</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Lasso - tresting selection as a hyper-parameter as random selection can significantly increase convergence time so may enable models to converge that wouldn&#39;t otherwise</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">Lasso</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">Lasso</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="s2">&quot;selection&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cyclic&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">]},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">lars</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Lars</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">Lars</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">Lars</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
                <span class="p">{</span><span class="s2">&quot;n_nonzero_coefs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="s2">&quot;jitter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="chemutil.classical_ml_models.neural_network_models">
    <p>def <span class="ident">neural_network_models</span>(</p><p>mlp: bool = True, layers: Tuple[Tuple[int]] = ((20, 10, 5), (50, 50, 50), (100, 50, 10), (100, 50, 25), (100, 50, 40)), solver: str = &#39;adam&#39;, max_iter: int = 400, n_input_features: Optional[int] = None, skip_feature_n_dependent: bool = False, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to build a default set of neural network models and parameter grids to optimize the models over</p>
<p>Returns:
    List[skmodel]: List of neural network models and meta data</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-chemutil.classical_ml_models.neural_network_models', this);">Show source &equiv;</a></p>
  <div id="source-chemutil.classical_ml_models.neural_network_models" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">neural_network_models</span><span class="p">(</span>
    <span class="n">mlp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">layers</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">n_input_features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">skip_feature_n_dependent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">skmodel</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">     Function to build a default set of neural network models and parameter grids to optimize the models over</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[skmodel]: List of neural network models and meta data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_input_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">skip_feature_n_dependent</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">hl1</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]</span>
        <span class="n">hl2</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>
        <span class="n">hl3</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_input_features</span> <span class="o">*</span> <span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hl1</span><span class="p">[</span><span class="n">ith</span><span class="p">],</span> <span class="n">hl2</span><span class="p">[</span><span class="n">ith</span><span class="p">],</span> <span class="n">hl3</span><span class="p">[</span><span class="n">ith</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">mlp</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Multi-layer perceptron (MLP) - This is the only general NN in sklearn currently. It is built as feedforward network.</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">skmodel</span><span class="p">(</span>
                <span class="nb">type</span><span class="p">(</span><span class="n">MLPRegressor</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">MLPRegressor</span><span class="p">(</span>
                    <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">helpers</span><span class="o">.</span><span class="n">random_seed</span>
                <span class="p">),</span>
                <span class="p">{</span>
                    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;const&quot;</span><span class="p">,</span> <span class="s2">&quot;invscaling&quot;</span><span class="p">,</span> <span class="s2">&quot;adaptive&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;learning_rate_init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
                    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.00001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span>
                    <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">:</span> <span class="n">layers</span><span class="p">,</span>
                    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
                <span class="p">},</span>
                <span class="p">{},</span>
                <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor&quot;</span><span class="p">,</span>
                <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
                <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">models</span>
</pre></div>

  </div>
</div>

  </div>


    <h2 class="section-title" id="header-classes">Classes</h2>

      <div class="item">
      <p id="chemutil.classical_ml_models.skmodel" class="name">class <span class="ident">skmodel</span></p>


    <div class="desc"><p>skmodel(name: str, model: Callable, default_param_grid: dict, custom_param_grid: dict, multi_output_regressor: bool, more_info: Optional[str] = None, sklearn_version: str = '1.6.1', date: str = datetime.datetime(2025, 5, 6, 13, 23, 33, 408156))</p></div>
  <div class="source_cont">
</div>


      <div class="class">
          <h3>Class variables</h3>
            <div class="item">
            <p id="chemutil.classical_ml_models.skmodel.date" class="name">var <span class="ident">date</span></p>




  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="chemutil.classical_ml_models.skmodel.more_info" class="name">var <span class="ident">more_info</span></p>




  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="chemutil.classical_ml_models.skmodel.sklearn_version" class="name">var <span class="ident">sklearn_version</span></p>




  <div class="source_cont">
</div>

            </div>
      </div>
      </div>

  </section>
</article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Generated by <a href="https://github.com/timothycrosley/pdocs">pdocs 1.2.0</a>
    </p>
  </footer>
</div>
</body>
</html>
